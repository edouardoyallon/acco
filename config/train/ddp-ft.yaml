group_by_length : false
batch_size: 4
n_grad_accumulation: 4
learning_rate : 2e-5
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.95
gradient_accumulation_steps : 1
nb_steps_tot: 50000 # alpaca
dataloader_num_workers : 1
dataloader_pin_memory : True
dataloader_persistent_workers : True
label_smoothing_factor : 0
max_length : 512
scheduler_name : 'cosine'
warmup : 0
save: False
use_mixed_precision: True
n_warmup_steps: 0
run_baseline_ddp: True
method_name: 'ddp'
eval: True
eval_step: 500
run_expe_slow: False
const_len_batch: False # set to false for finetuning
finetune: True