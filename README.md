# ACCO: Accumulate While You Communicate

![ACCO Diagram](./representation_acco.png)

This repository implements **ACCO**, introduced in the paper:  
**"ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training"**

Authors:  
Adel NabliÂ¹Â², Louis FournierÂ¹, Pierre ErbacherÂ¹, Louis SerranoÂ¹, Eugene BelilovskyÂ², Edouard OyallonÂ¹  
Â¹Sorbonne UniversitÃ©, CNRS, ISIR â€” Paris, France  
Â²Mila â€” Quebec AI Institute, Concordia University â€” MontrÃ©al, QuÃ©bec  
ğŸ“§ adel.nabli@sorbonne-universite.fr, edouard.oyallon@cnrs.fr

---

## ğŸ“„ Citation

If you use this work, please cite:

```bibtex
@misc{nabli2025accoaccumulatecommunicatecommunicationoverlapped,
      title={ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training}, 
      author={Adel Nabli and Louis Fournier and Pierre Erbacher and Louis Serrano and Eugene Belilovsky and Edouard Oyallon},
      year={2025},
      eprint={2406.02613},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.02613}, 
}
```

ğŸ“ [View the paper on arXiv](https://arxiv.org/abs/2406.02613)

---

## ğŸš€ Overview

ACCO is a memory-efficient and communication-overlapping optimization algorithm for distributed LLM training. It decouples gradient synchronization and optimizer updates, reducing GPU idle time and supporting optimizer state sharding across heterogeneous clusters.

Compared to ZeRO:
- âœ… Reduces communication bottlenecks  
- âœ… Supports sharded optimizers  
- âœ… Scales across heterogeneous hardware  
- âœ… Matches or exceeds standard DDP performance

---

## ğŸ§ª Training

Run training with ACCO or standard DDP:

```bash
# Launch ACCO training
python main.py train=acco

# Launch DDP training
python main.py train=ddp
```

---

## ğŸ“ Dataset Download Example

```python
import os
from datasets import load_dataset

os.environ['HF_HOME'] = 'mypath/.cache/huggingface'
dataset = load_dataset("Skylion007/openwebtext")
```

---

## ğŸ§¼ Finetuning Example

```bash
# Finetune using ACCO
srun python main.py train=acco-ft data=alpaca model=llama3

# Finetune using DDP
srun python main.py train=ddp-ft data=alpaca model=llama3
```

---

## âš™ï¸ Asynchronous Training with `DecoupledTrainer`

```python
from transformers import AutoTokenizer, LlamaConfig, LlamaForCausalLM
from datasets import load_dataset
from decoupled_trainer import DecoupledTrainer

# Model setup
model_config = LlamaConfig(**model_cfg)
model = LlamaForCausalLM(model_config)
tokenizer = AutoTokenizer.from_pretrained("my_tokenizer")
dataset = load_dataset("my_dataset")

# Replace HF Trainer with DecoupledTrainer
trainer = DecoupledTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    text_column_name="text",
    args=train_config
)

trainer.train()
```
